"""
SYSTEM DESIGN: CTR PREDICTION AT 30B REQUESTS/DAY
Complete architecture for Criteo-scale operations
Interview-ready with diagrams and calculations
"""

from dataclasses import dataclass
from typing import Dict, List, Optional
import math


@dataclass
class SystemRequirements:
    """Real Criteo scale requirements"""
    daily_requests = 30_000_000_000  # 30B/day
    qps_average = 350_000  # Average QPS
    qps_peak = 1_000_000  # Peak QPS
    latency_p50_ms = 5  # 50th percentile
    latency_p99_ms = 10  # 99th percentile
    availability = 0.9999  # 4 nines
    ctr_average = 0.002  # 0.2% CTR
    feature_size_bytes = 1000  # Per request
    model_size_gb = 10  # Trained model


class SystemArchitecture:
    """Complete system design for CTR at scale"""
    
    def __init__(self):
        self.requirements = SystemRequirements()
        
    def calculate_infrastructure(self) -> Dict:
        """Calculate infrastructure needs"""
        
        # 1. COMPUTE REQUIREMENTS
        # Assuming 1ms processing time per request
        servers_for_qps = math.ceil(self.requirements.qps_peak / 10000)  # 10K QPS per server
        
        # Add redundancy (N+2)
        total_servers = servers_for_qps + 2
        
        # 2. MEMORY REQUIREMENTS
        # Model in memory per server
        memory_per_server_gb = self.requirements.model_size_gb + 32  # 32GB for OS/buffer
        
        # Feature cache (1M requests * 1KB)
        cache_memory_gb = 1_000_000 * self.requirements.feature_size_bytes / (1024**3)
        
        # 3. STORAGE REQUIREMENTS
        # Daily logs
        daily_storage_tb = (self.requirements.daily_requests * 
                          self.requirements.feature_size_bytes / (1024**4))
        
        # With compression (10:1 ratio)
        compressed_storage_tb = daily_storage_tb / 10
        
        # 4. NETWORK REQUIREMENTS
        bandwidth_gbps = (self.requirements.qps_peak * 
                         self.requirements.feature_size_bytes * 8 / (1024**3))
        
        return {
            'compute': {
                'servers_needed': total_servers,
                'cores_per_server': 64,
                'total_cores': total_servers * 64
            },
            'memory': {
                'per_server_gb': memory_per_server_gb,
                'total_memory_tb': total_servers * memory_per_server_gb / 1024,
                'cache_size_gb': cache_memory_gb
            },
            'storage': {
                'daily_raw_tb': daily_storage_tb,
                'daily_compressed_tb': compressed_storage_tb,
                'yearly_compressed_pb': compressed_storage_tb * 365 / 1024
            },
            'network': {
                'bandwidth_gbps': bandwidth_gbps,
                'connections_per_second': self.requirements.qps_peak
            }
        }
    
    def get_architecture_components(self) -> str:
        """Return complete architecture design"""
        
        architecture = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                  CRITEO CTR SYSTEM ARCHITECTURE                   â•‘
â•‘                    30B Requests/Day @ <10ms P99                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        TIER 1: EDGE LAYER                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   CDN    â”‚  â”‚   CDN    â”‚  â”‚   CDN    â”‚  â”‚   CDN    â”‚       â”‚
â”‚  â”‚  (US)    â”‚  â”‚  (EU)    â”‚  â”‚  (Asia)  â”‚  â”‚  (LATAM) â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â”‚
â”‚        â”‚             â”‚             â”‚             â”‚              â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                             â”‚                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     TIER 2: API GATEWAY                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚            Load Balancer (L4/L7)                       â”‚     â”‚
â”‚  â”‚    - Geographic routing                                â”‚     â”‚
â”‚  â”‚    - SSL termination                                   â”‚     â”‚
â”‚  â”‚    - Rate limiting (per publisher)                    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                   â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚            API Gateway Cluster                         â”‚     â”‚
â”‚  â”‚    - Request validation                                â”‚     â”‚
â”‚  â”‚    - Feature extraction                                â”‚     â”‚
â”‚  â”‚    - Request batching                                  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                   â”‚                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 TIER 3: PREDICTION SERVICE                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                   Feature Store                           â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   â”‚
â”‚  â”‚  â”‚   Redis     â”‚  â”‚  Aerospike  â”‚  â”‚   DynamoDB  â”‚      â”‚   â”‚
â”‚  â”‚  â”‚  (Hot Data) â”‚  â”‚  (User Prof)â”‚  â”‚  (Historical)â”‚     â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                             â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                Model Serving Layer                        â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚   â”‚
â”‚  â”‚  â”‚ TensorFlow â”‚  â”‚   PyTorch  â”‚  â”‚  LightGBM  â”‚         â”‚   â”‚
â”‚  â”‚  â”‚  Serving   â”‚  â”‚   Serve    â”‚  â”‚   Server   â”‚         â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â”‚  - Model A/B testing                                      â”‚   â”‚
â”‚  â”‚  - Online learning updates                                â”‚   â”‚
â”‚  â”‚  - Ensemble predictions                                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                             â”‚                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TIER 4: BIDDING ENGINE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                 Real-Time Bidder (RTB)                    â”‚   â”‚
â”‚  â”‚  - Bid price calculation: bid = CTR Ã— CPC Ã— 1000         â”‚   â”‚
â”‚  â”‚  - Budget pacing algorithms                               â”‚   â”‚
â”‚  â”‚  - Auction participation logic                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                             â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Campaign Management Service                   â”‚   â”‚
â”‚  â”‚  - Budget tracking                                        â”‚   â”‚
â”‚  â”‚  - Frequency capping                                      â”‚   â”‚
â”‚  â”‚  - Targeting rules                                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  TIER 5: DATA PIPELINE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                   Stream Processing                        â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   â”‚
â”‚  â”‚  â”‚   Kafka     â”‚â†’ â”‚    Flink    â”‚â†’ â”‚  Cassandra  â”‚      â”‚   â”‚
â”‚  â”‚  â”‚  (Ingestion)â”‚  â”‚ (Processing)â”‚  â”‚  (Storage)  â”‚      â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                   Batch Processing                         â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   â”‚
â”‚  â”‚  â”‚    HDFS     â”‚â†’ â”‚    Spark    â”‚â†’ â”‚    Hive     â”‚      â”‚   â”‚
â”‚  â”‚  â”‚   (Data)    â”‚  â”‚  (Training) â”‚  â”‚  (Warehouse)â”‚      â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                TIER 6: MONITORING & OPERATIONS                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    Observability Stack                     â”‚   â”‚
â”‚  â”‚  â€¢ Metrics: Prometheus + Grafana                          â”‚   â”‚
â”‚  â”‚  â€¢ Logging: ELK Stack (Elasticsearch, Logstash, Kibana)   â”‚   â”‚
â”‚  â”‚  â€¢ Tracing: Jaeger / Zipkin                               â”‚   â”‚
â”‚  â”‚  â€¢ Alerting: PagerDuty + OpsGenie                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""
        return architecture
    
    def get_data_flow(self) -> str:
        """Data flow through the system"""
        
        flow = """
DATA FLOW SEQUENCE (Request to Response):

1. REQUEST INGESTION (0-1ms)
   Client â†’ CDN â†’ Load Balancer â†’ API Gateway
   - Geographic routing
   - SSL termination
   - Request validation

2. FEATURE ENRICHMENT (1-2ms)
   API Gateway â†’ Feature Store
   - User profile lookup (Redis)
   - Publisher data (Aerospike)
   - Historical CTR (DynamoDB)
   
3. PREDICTION (2-4ms)
   Feature Vector â†’ Model Server
   - Ensemble of models
   - A/B test assignment
   - Score calculation
   
4. BIDDING DECISION (4-5ms)
   CTR Score â†’ Bidding Engine
   - Budget check
   - Bid calculation
   - Auction participation
   
5. RESPONSE (5-6ms)
   Bid Response â†’ Client
   - Async logging
   - Metrics emission

TOTAL LATENCY: <10ms P99

DATA PERSISTENCE FLOW:

1. REAL-TIME STREAM
   Events â†’ Kafka â†’ Flink â†’ Feature Store
   - Click/impression events
   - User behavior updates
   - Campaign performance

2. BATCH PROCESSING
   HDFS â†’ Spark â†’ Model Training
   - Daily model retraining
   - Feature engineering
   - Performance analysis

3. ONLINE LEARNING
   Stream â†’ Online Learner â†’ Model Update
   - Incremental updates
   - Concept drift handling
   - Real-time adaptation
"""
        return flow
    
    def get_optimization_strategies(self) -> str:
        """Performance optimization techniques"""
        
        optimizations = """
PERFORMANCE OPTIMIZATIONS:

1. CACHING STRATEGIES
   â€¢ L1: Application cache (local memory) - 0.1ms
   â€¢ L2: Redis (hot data) - 1ms
   â€¢ L3: Aerospike (warm data) - 5ms
   â€¢ L4: DynamoDB (cold data) - 10ms
   
   Cache Hit Ratios:
   - User profiles: 95% (LRU with 1M entries)
   - Publisher data: 99% (static, refreshed hourly)
   - Model predictions: 80% (TTL: 5 minutes)

2. MODEL SERVING OPTIMIZATIONS
   â€¢ Quantization: INT8 inference (4x speedup)
   â€¢ Batching: Dynamic batching (10-100 requests)
   â€¢ GPU inference: For deep models only
   â€¢ Model pruning: 90% sparsity, 2x speedup
   â€¢ ONNX runtime: Cross-platform optimization

3. FEATURE ENGINEERING
   â€¢ Pre-computed features in Feature Store
   â€¢ Approximate algorithms (Count-Min Sketch)
   â€¢ Sampling for non-critical features
   â€¢ Vectorized operations (SIMD)
   â€¢ Feature hashing for categoricals

4. NETWORK OPTIMIZATIONS
   â€¢ Connection pooling
   â€¢ HTTP/2 with multiplexing
   â€¢ Protobuf for serialization
   â€¢ Regional deployments
   â€¢ Anycast routing

5. DATABASE OPTIMIZATIONS
   â€¢ Sharding by user_id (consistent hashing)
   â€¢ Read replicas for hot data
   â€¢ Materialized views for aggregates
   â€¢ Bloom filters for existence checks
   â€¢ Columnar storage for analytics

6. SCALING STRATEGIES
   â€¢ Horizontal scaling: Add servers
   â€¢ Vertical scaling: GPU for deep learning
   â€¢ Auto-scaling based on QPS
   â€¢ Spot instances for batch jobs
   â€¢ Reserved capacity for baseline

7. FAILURE HANDLING
   â€¢ Circuit breakers (Hystrix pattern)
   â€¢ Graceful degradation
   â€¢ Fallback to simple models
   â€¢ Request hedging for critical paths
   â€¢ Chaos engineering tests

COST OPTIMIZATIONS:

1. INFRASTRUCTURE
   â€¢ Spot instances: 70% cost reduction for batch
   â€¢ Reserved instances: 40% for baseline capacity
   â€¢ Auto-scaling: Scale down during low traffic
   â€¢ Multi-cloud: Leverage best prices

2. DATA STORAGE
   â€¢ Tiered storage (Hot/Warm/Cold)
   â€¢ Compression (10:1 for logs)
   â€¢ Data retention policies
   â€¢ Deduplication

3. MODEL SERVING
   â€¢ Model distillation (smaller models)
   â€¢ Edge inference where possible
   â€¢ Cached predictions
   â€¢ Approximate inference for low-value requests
"""
        return optimizations
    
    def get_monitoring_metrics(self) -> str:
        """Key metrics to monitor"""
        
        metrics = """
KEY MONITORING METRICS:

BUSINESS METRICS:
â€¢ CTR (Click-Through Rate)
  - Overall: Target > 0.2%
  - By segment: User, Publisher, Device
  - Trend: Hour-over-hour, Day-over-day
  
â€¢ Revenue Metrics
  - RPM (Revenue per 1000 impressions)
  - Fill rate
  - Win rate in auctions
  - Average bid price

â€¢ Campaign Performance
  - Budget utilization
  - Conversion rate
  - ROI/ROAS

TECHNICAL METRICS:
â€¢ Latency
  - P50: < 5ms
  - P95: < 8ms  
  - P99: < 10ms
  - P99.9: < 20ms
  
â€¢ Throughput
  - QPS: Current vs capacity
  - Request success rate: > 99.99%
  - Error rate by type
  
â€¢ Model Performance
  - AUC: > 0.80
  - LogLoss: < 0.45
  - Calibration ratio
  - Feature importance drift

â€¢ Infrastructure
  - CPU utilization: < 70%
  - Memory usage: < 80%
  - Network I/O
  - Disk I/O
  - Cache hit rates

â€¢ Data Pipeline
  - Kafka lag
  - Processing delay
  - Data completeness
  - Schema violations

ALERTING THRESHOLDS:
â€¢ Critical: CTR drop > 20%, Latency P99 > 15ms
â€¢ High: Error rate > 1%, CPU > 90%
â€¢ Medium: Cache hit < 80%, Model drift detected
â€¢ Low: Disk usage > 70%, Training delay > 1hr

DASHBOARDS:
1. Executive Dashboard
   - Revenue, CTR, Fill rate
   - Top campaigns performance

2. Operations Dashboard
   - System health, Latency, QPS
   - Error rates, Alerts

3. Model Dashboard
   - Model versions, A/B tests
   - Performance metrics, Drift

4. Publisher Dashboard
   - Publisher-specific metrics
   - Revenue, CTR by placement
"""
        return metrics


def generate_capacity_planning():
    """Generate capacity planning calculations"""
    
    arch = SystemArchitecture()
    infra = arch.calculate_infrastructure()
    
    planning = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                     CAPACITY PLANNING                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TRAFFIC ANALYSIS:
â€¢ Daily Requests: {arch.requirements.daily_requests:,}
â€¢ Average QPS: {arch.requirements.qps_average:,}
â€¢ Peak QPS: {arch.requirements.qps_peak:,}
â€¢ Peak/Average Ratio: {arch.requirements.qps_peak/arch.requirements.qps_average:.1f}x

COMPUTE REQUIREMENTS:
â€¢ Servers Needed: {infra['compute']['servers_needed']}
â€¢ Cores per Server: {infra['compute']['cores_per_server']}
â€¢ Total Cores: {infra['compute']['total_cores']:,}
â€¢ Redundancy: N+2

MEMORY REQUIREMENTS:
â€¢ Per Server: {infra['memory']['per_server_gb']} GB
â€¢ Total Memory: {infra['memory']['total_memory_tb']:.1f} TB
â€¢ Cache Size: {infra['memory']['cache_size_gb']:.1f} GB

STORAGE REQUIREMENTS:
â€¢ Daily Raw Data: {infra['storage']['daily_raw_tb']:.1f} TB
â€¢ Daily Compressed: {infra['storage']['daily_compressed_tb']:.1f} TB
â€¢ Yearly Storage: {infra['storage']['yearly_compressed_pb']:.1f} PB

NETWORK REQUIREMENTS:
â€¢ Bandwidth: {infra['network']['bandwidth_gbps']:.1f} Gbps
â€¢ Connections/sec: {infra['network']['connections_per_second']:,}

COST ESTIMATION (AWS):
â€¢ Compute (EC2): ~${infra['compute']['servers_needed'] * 5000}/month
â€¢ Storage (S3): ~${infra['storage']['daily_compressed_tb'] * 30 * 23}/month
â€¢ Network (Transfer): ~${infra['network']['bandwidth_gbps'] * 100}/month
â€¢ Total: ~${infra['compute']['servers_needed'] * 5000 + infra['storage']['daily_compressed_tb'] * 30 * 23 + infra['network']['bandwidth_gbps'] * 100:,}/month
"""
    return planning


def interview_talking_points():
    """Key points to discuss in interview"""
    
    points = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    INTERVIEW TALKING POINTS                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. SCALABILITY CHALLENGES
   â€¢ "At 30B requests/day, we need 1M QPS peak capacity"
   â€¢ "Horizontal scaling with consistent hashing for sharding"
   â€¢ "Multi-region deployment for global latency < 50ms"

2. LATENCY OPTIMIZATIONS  
   â€¢ "Every millisecond counts - 100ms delay = 1% revenue loss"
   â€¢ "Feature caching saves 3-4ms per request"
   â€¢ "Model quantization gives 4x speedup with minimal accuracy loss"

3. REAL-TIME REQUIREMENTS
   â€¢ "Sub-10ms response time for 100ms RTB timeout"
   â€¢ "Online learning for immediate feedback incorporation"
   â€¢ "Stream processing for real-time feature updates"

4. COST EFFICIENCY
   â€¢ "Spot instances for 70% cost reduction on batch jobs"
   â€¢ "Tiered storage: hot (Redis), warm (Aerospike), cold (S3)"
   â€¢ "Model distillation reduces serving costs by 50%"

5. RELIABILITY
   â€¢ "99.99% availability = 52 minutes downtime/year max"
   â€¢ "Multi-region failover with <1 minute RTO"
   â€¢ "Graceful degradation - fallback to simple models"

6. MACHINE LEARNING AT SCALE
   â€¢ "Distributed training on Spark for TB-scale data"
   â€¢ "A/B testing framework for continuous improvement"
   â€¢ "Feature store for consistency between training/serving"

7. PRIVACY & COMPLIANCE
   â€¢ "GDPR compliance with user consent management"
   â€¢ "Differential privacy for user features"
   â€¢ "Data retention policies and right-to-be-forgotten"

8. INNOVATION OPPORTUNITIES
   â€¢ "Transformer models for sequential user behavior"
   â€¢ "Federated learning for privacy-preserving training"
   â€¢ "Reinforcement learning for bid optimization"

CRITEO-SPECIFIC INSIGHTS:
â€¢ "Criteo processes 30B+ requests daily across 20K+ publishers"
â€¢ "Sub-2ms model inference using optimized C++ implementations"
â€¢ "Proprietary Criteo Engine handles 600K QPS per datacenter"
â€¢ "DeepKNN for candidate retrieval from 1B+ products"
"""
    return points


if __name__ == "__main__":
    print("\nğŸ—ï¸ SYSTEM DESIGN: CTR @ CRITEO SCALE\n")
    
    arch = SystemArchitecture()
    
    # Show architecture
    print(arch.get_architecture_components())
    
    # Show data flow
    print("\n" + "=" * 70)
    print(arch.get_data_flow())
    
    # Show optimizations
    print("\n" + "=" * 70)
    print(arch.get_optimization_strategies())
    
    # Show monitoring
    print("\n" + "=" * 70)
    print(arch.get_monitoring_metrics())
    
    # Show capacity planning
    print("\n" + "=" * 70)
    print(generate_capacity_planning())
    
    # Show interview points
    print("\n" + "=" * 70)
    print(interview_talking_points())
    
    print("\n" + "=" * 70)
    print("âœ… SYSTEM DESIGN MODULE COMPLETE!")
    print("=" * 70)
    print("\nğŸ¯ Ready for Criteo system design interview!")
    print("  â€¢ Complete architecture documented")
    print("  â€¢ Scalability calculations ready")
    print("  â€¢ Cost optimizations identified")
    print("  â€¢ Monitoring strategy defined")
    print("  â€¢ Interview talking points prepared")